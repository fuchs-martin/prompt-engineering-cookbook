# prompt-engineering-cookbook
A structured collection of prompt engineering templates, techniques and patterns.

## Introduction

Working with *large language models (LLMs)* can be diverse, unpredictable, and even inaccurate if we don’t know how to use them properly. Based on the need for more precise, correct, predictable, and controllable answers, a new discipline has emerged for developers and for optimizing prompts — **prompt engineering**.

Prompt engineering helps us understand how LLMs behave, how they interpret instructions, and how to shape inputs so that the model produces the exact type of output we need. It gives developers control over the model’s “reasoning,” structure, and style of response.

The core idea is simple:
**well-designed input → high-quality output.**

In practice, this involves techniques such as:
-isolating content with delimiters,
-structuring output into HTML or JSON,
-enforcing specific rules or constraints,
-guiding the model through examples (few-shot prompting),
-refining responses iteratively,
-transforming, summarizing, or expanding text,
-shaping tone or style,
-or applying reasoning patterns like chain-of-thought or multi-step reasoning.

This Prompt Engineering Cookbook brings together the most practical techniques used by professionals — and by me — to achieve predictable and high-quality results when working with LLMs.

## Delimiters

## Structured Outputs (HTML, JSON)

## Verifying Conditions

## Few-Shot Prompting

## Iterative Prompting

## Summarizing

## Inferring

## Transforming

## Expanding

## Chain-of-Thought Reasoning

## Chaining Prompts

## Appendix